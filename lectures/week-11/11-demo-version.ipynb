{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86b95a4-df79-4f8c-b0fb-b21f89a8fe7e",
   "metadata": {},
   "source": [
    "# Demo Notebook - Lecture 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26ed3d-73a1-41f0-a051-c6fb44e34418",
   "metadata": {},
   "source": [
    "In this lecture, we will investigate different methods for clustering time series:\n",
    "- Aggregating the data\n",
    "- Using distance metrics that can handle vectors (e.g. Euclidean distance)\n",
    "- Using dynamic time warping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5117d9-84e9-4114-b2bf-b0c900acbd4a",
   "metadata": {},
   "source": [
    "We will use spectral clustering for all experiments. Furthermore, we will again use a synthetic data set to explore the characteristics of the different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49821ae9-be3e-4bc1-9695-ef6c2cac6fbb",
   "metadata": {},
   "source": [
    "Using our synthetic data, we are interested in exploring procrastination. For this purpose, we will cluster the data of 30 high-school students based on their usage of an academic learning platform. The dataset contains the number of hours per biweek of the year that each student spent on the platform.\n",
    "\n",
    "The dataset  is described by the following columns:\n",
    "\n",
    "- student id: unique student identifier-\n",
    "- biweek of the year: number of the biweek of the school year. Biweek 0 refers to the first two wekeks of the school year.\n",
    "- hours: number of hours the student spent on the platform for that particular biweek-\n",
    "- student type: expert tagging of student behavior, where (1) is procrastinators, (2) regular students, and (3) precrastinators. We will use the expert label as ground truth for the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f9e6e-1ffa-46cb-b720-d4fbc32705d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:57:08.752632Z",
     "iopub.status.busy": "2025-04-28T14:57:08.750563Z",
     "iopub.status.idle": "2025-04-28T14:57:18.676809Z",
     "shell.execute_reply": "2025-04-28T14:57:18.675576Z",
     "shell.execute_reply.started": "2025-04-28T14:57:08.752571Z"
    }
   },
   "outputs": [],
   "source": [
    "#Important imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy import linalg\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import spectral_embedding\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e75d50-bce4-47ff-8f1f-3b6b83b283f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:15.341678Z",
     "iopub.status.busy": "2025-04-28T14:59:15.341293Z",
     "iopub.status.idle": "2025-04-28T14:59:15.368307Z",
     "shell.execute_reply": "2025-04-28T14:59:15.365293Z",
     "shell.execute_reply.started": "2025-04-28T14:59:15.341649Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('{}/hours_biweek_students.csv'.format(DATA_DIR))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef31d8-b337-43e9-a895-69675a4effc9",
   "metadata": {},
   "source": [
    "In a first step, we extract a time series (of biweeks) for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af655c8d-8ecf-42c9-9429-3c6898997bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:18.263149Z",
     "iopub.status.busy": "2025-04-28T14:59:18.261061Z",
     "iopub.status.idle": "2025-04-28T14:59:18.292611Z",
     "shell.execute_reply": "2025-04-28T14:59:18.290263Z",
     "shell.execute_reply.started": "2025-04-28T14:59:18.263016Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_series(df):\n",
    "    \"\"\"\n",
    "    reshapes DataFrame from long to wide and returns an np.array\n",
    "    :param df: pd.DataFrame with data in long format\n",
    "    :return: np.array with reshaped data\n",
    "    \"\"\"\n",
    "    df_array = (df.sort_values(['student_id', 'biweek_of_year'], ascending=True)\n",
    "                .groupby('student_id')\n",
    "                .agg({'hours': lambda x: list(x)}))\n",
    "\n",
    "    data = np.asarray(df_array.hours.values.tolist())\n",
    "    return data\n",
    "\n",
    "\n",
    "data = get_time_series(df)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c7171-7cc8-4d6f-9499-a9bd0a074391",
   "metadata": {},
   "source": [
    "We then plot the time series data for each student. The three student types are visually very well separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030959f-513f-4a82-9eb6-13d0677d430a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:19.484204Z",
     "iopub.status.busy": "2025-04-28T14:59:19.483362Z",
     "iopub.status.idle": "2025-04-28T14:59:26.029566Z",
     "shell.execute_reply": "2025-04-28T14:59:26.028422Z",
     "shell.execute_reply.started": "2025-04-28T14:59:19.484029Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_students(data):\n",
    "    \"\"\"\n",
    "    Plot the students time-series\n",
    "    :param data: np.array with students' time-series\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    students, biweeks = data.shape\n",
    "    fig, axs = plt.subplots(5, 6, figsize=(16, 10), sharex=True,\n",
    "                            sharey=True, facecolor='w', edgecolor='k')\n",
    "    axs = axs.ravel()\n",
    "    for i in range(students):\n",
    "        axs[i].bar(range(biweeks), data[i], alpha=0.8)\n",
    "        axs[i].set_ylim([0, 50])\n",
    "        axs[i].set_title('Student {0}'.format(i))\n",
    "    fig.text(0.5, 0.09, 'Biweek', va='center', ha='center', fontsize=14)\n",
    "    fig.text(0.09, 0.5, 'Usage of platform (hours)', va='center', ha='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "\n",
    "plot_students(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95544ed-8cb7-420c-812c-c83cbe937d9e",
   "metadata": {},
   "source": [
    "Next, we implement some helper functions needed to perform spectral clustering. Specifically, we provide the following functions:\n",
    "- get_adjacency: computes the adjacency matrix W from a pairwise similarity matrix S\n",
    "- spectral_clustering: performs spectral clustering for a given number of clusters k, based on an adjacency matrix W\n",
    "- get_heuristics_spectral: performs spectral clustering for k=2,...,n clusters and computes the Silhouette score and eigengap heuristic for each k\n",
    "- plot_metrics: visualizes the heuristics for the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30c9d8-bebf-42dc-b7f4-340601276b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:26.031745Z",
     "iopub.status.busy": "2025-04-28T14:59:26.031447Z",
     "iopub.status.idle": "2025-04-28T14:59:26.039563Z",
     "shell.execute_reply": "2025-04-28T14:59:26.038474Z",
     "shell.execute_reply.started": "2025-04-28T14:59:26.031717Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adjacency(S, connectivity='full'):\n",
    "    \"\"\"\n",
    "    Computes the adjacency matrix\n",
    "    :param S: np array of similarity matrix\n",
    "    :param connectivity: type of connectivity \n",
    "    :return: adjacency matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    if(connectivity=='full'):\n",
    "        adjacency = S\n",
    "    elif(connectivity=='epsilon'):\n",
    "        epsilon = 0.5\n",
    "        adjacency = np.where(S > epsilon, 1, 0)\n",
    "    else:\n",
    "        raise RuntimeError('Method not supported')\n",
    "        \n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794d1ce-8a19-47c4-a19d-a75f59cf853b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:26.040988Z",
     "iopub.status.busy": "2025-04-28T14:59:26.040702Z",
     "iopub.status.idle": "2025-04-28T14:59:26.097198Z",
     "shell.execute_reply": "2025-04-28T14:59:26.094331Z",
     "shell.execute_reply.started": "2025-04-28T14:59:26.040962Z"
    }
   },
   "outputs": [],
   "source": [
    "def spectral_clustering(W, n_clusters, random_state=111):\n",
    "    \"\"\"\n",
    "    Spectral clustering\n",
    "    :param W: np array of adjacency matrix\n",
    "    :param n_clusters: number of clusters\n",
    "    :return: tuple (kmeans, proj_X, eigenvals_sorted)\n",
    "        WHERE\n",
    "        kmeans scikit learn clustering object\n",
    "        proj_X is np array of transformed data points\n",
    "        eigenvals_sorted is np array with ordered eigenvalues \n",
    "        \n",
    "    \"\"\"\n",
    "    # Compute eigengap heuristic\n",
    "    L = laplacian(W, normed=True)\n",
    "    eigenvals, _ = linalg.eig(L)\n",
    "    eigenvals = np.real(eigenvals)\n",
    "    eigenvals_sorted = eigenvals[np.argsort(eigenvals)]\n",
    "\n",
    "    # Create embedding\n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    proj_X = spectral_embedding(W, n_components=n_clusters,\n",
    "                              random_state=random_state,\n",
    "                              drop_first=False)\n",
    "\n",
    "    # Cluster the points using k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state = random_state)\n",
    "    kmeans.fit(proj_X)\n",
    "\n",
    "    return kmeans, proj_X, eigenvals_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b029fc-9054-40f1-ad54-072a1d496fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:28.564956Z",
     "iopub.status.busy": "2025-04-28T14:59:28.564131Z",
     "iopub.status.idle": "2025-04-28T14:59:28.582579Z",
     "shell.execute_reply": "2025-04-28T14:59:28.580584Z",
     "shell.execute_reply.started": "2025-04-28T14:59:28.564890Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metrics(n_clusters_list, metric_dictionary):\n",
    "    \"\"\"\n",
    "    Plots metric dictionary (auxilary function)\n",
    "    [Optional]\n",
    "    \n",
    "    :param n_clusters_list: List of number of clusters to explore \n",
    "    :param metric_dictionary: \n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12, 10), dpi=80)\n",
    "    i = 1\n",
    "\n",
    "    for metric in metric_dictionary.keys():\n",
    "        plt.subplot(3, 2, i)\n",
    "\n",
    "        if metric == 'Eigengap':\n",
    "            clusters = len(n_clusters_list)\n",
    "            eigenvals_sorted = metric_dictionary[metric]\n",
    "            plt.scatter(range(1, len(eigenvals_sorted[:clusters * 2]) + 1), eigenvals_sorted[:clusters * 2])\n",
    "            plt.xlabel('Eigenvalues')\n",
    "            plt.xticks(range(1, len(eigenvals_sorted[:clusters * 2]) + 1))\n",
    "        else:\n",
    "            plt.plot(n_clusters_list, metric_dictionary[metric], '-o')\n",
    "            plt.xlabel('Number of clusters')\n",
    "            plt.xticks(n_clusters_list)\n",
    "        plt.ylabel(metric)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d494d0a-81ff-4475-ad92-5151aac2dd0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:29.358294Z",
     "iopub.status.busy": "2025-04-28T14:59:29.357211Z",
     "iopub.status.idle": "2025-04-28T14:59:29.373988Z",
     "shell.execute_reply": "2025-04-28T14:59:29.371811Z",
     "shell.execute_reply.started": "2025-04-28T14:59:29.358228Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_heuristics_spectral(W, n_clusters_list, plot=True):\n",
    "    \"\"\"\n",
    "    Calculates heuristics for optimal number of clusters with Spectral Clustering\n",
    "    \n",
    "    :param W: np array of adjacency matrix\n",
    "    :param n_clusters_list: List of number of clusters to explore\n",
    "    :plot: bool, plot the metrics if true\n",
    "    \"\"\"\n",
    "    silhouette_list = []\n",
    "    eigengap_list = []\n",
    "    \n",
    "    df_labels = pd.DataFrame()\n",
    "\n",
    "    for k in n_clusters_list:\n",
    "\n",
    "        kmeans, proj_X, eigenvals_sorted = spectral_clustering(W, k)\n",
    "        y_pred = kmeans.labels_\n",
    "        df_labels[str(k)] = y_pred\n",
    "\n",
    "        if k == 1:\n",
    "            silhouette = np.nan\n",
    "        else:\n",
    "            silhouette = silhouette_score(proj_X, y_pred)\n",
    "        silhouette_list.append(silhouette)\n",
    "\n",
    "\n",
    "    metric_dictionary = {\n",
    "                         'Silhouette': silhouette_list,\n",
    "                         'Eigengap': eigenvals_sorted,\n",
    "                        }\n",
    "    \n",
    "    if(plot):\n",
    "        plot_metrics(n_clusters_list, metric_dictionary)\n",
    "        return df_labels\n",
    "    else:\n",
    "        return df_labels, metric_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9f37c-b91b-47c5-8eda-dc075483dc51",
   "metadata": {},
   "source": [
    "## 1 - Aggregated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b567e7f-2c21-4b15-8cef-09b3c664ee23",
   "metadata": {},
   "source": [
    "The first method we will explore is aggregating features over time. In our example, we will use the mean for the aggreation. We therefore first compute the mean value of our feature (number of hours per biweek) over the whole time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0410d-20c4-492f-b37c-a62d94bcdb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:31.167698Z",
     "iopub.status.busy": "2025-04-28T14:59:31.165230Z",
     "iopub.status.idle": "2025-04-28T14:59:31.423820Z",
     "shell.execute_reply": "2025-04-28T14:59:31.422607Z",
     "shell.execute_reply.started": "2025-04-28T14:59:31.167600Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute the average of the feature over the whole time series\n",
    "aggregated_data = np.mean(data, axis = 1)\n",
    "\n",
    "# plot the histogram of the feature for all students\n",
    "plt.hist(aggregated_data, bins = 6, alpha = 0.3, color = 'blue')\n",
    "plt.xlabel('Mean number of hours per biweek')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf3d34-2bb2-4217-a1ac-63d9ccb4e8f5",
   "metadata": {},
   "source": [
    "We then again build a similarity matrix and a similarity graph and perform spectral clustering for k=2,...10 clusters. We visualize the Silhouette score and the eigengap heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35db1b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:32.598542Z",
     "iopub.status.busy": "2025-04-28T14:59:32.595605Z",
     "iopub.status.idle": "2025-04-28T14:59:32.630421Z",
     "shell.execute_reply": "2025-04-28T14:59:32.627329Z",
     "shell.execute_reply.started": "2025-04-28T14:59:32.598406Z"
    }
   },
   "outputs": [],
   "source": [
    "S = pairwise_kernels(aggregated_data.reshape(-1,1), metric='rbf', gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb2d35-c627-45e0-8b63-366730e39ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:32.952541Z",
     "iopub.status.busy": "2025-04-28T14:59:32.950403Z",
     "iopub.status.idle": "2025-04-28T14:59:32.962453Z",
     "shell.execute_reply": "2025-04-28T14:59:32.960509Z",
     "shell.execute_reply.started": "2025-04-28T14:59:32.952443Z"
    }
   },
   "outputs": [],
   "source": [
    "W =  get_adjacency(S) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada74e85-422f-435f-ac1f-f4c4b77cf91c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:33.379706Z",
     "iopub.status.busy": "2025-04-28T14:59:33.379317Z",
     "iopub.status.idle": "2025-04-28T14:59:33.890431Z",
     "shell.execute_reply": "2025-04-28T14:59:33.888395Z",
     "shell.execute_reply.started": "2025-04-28T14:59:33.379676Z"
    }
   },
   "outputs": [],
   "source": [
    "n_cluster_list = range(2, 10)\n",
    "df_labels = get_heuristics_spectral(W, n_cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec27ad5-d2d5-488b-a4a3-d58d647d75f7",
   "metadata": {},
   "source": [
    "Next, we want to visualize the time series of the students in the different clusters. We implement a function `view_clusters`, which visualizes the average behavior for each cluster. We also implement a function `plot_students_group`, which visualizes the time series of the students in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5577c0b-5d96-4afd-82ca-779ebf04a779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:34.763887Z",
     "iopub.status.busy": "2025-04-28T14:59:34.762898Z",
     "iopub.status.idle": "2025-04-28T14:59:34.777049Z",
     "shell.execute_reply": "2025-04-28T14:59:34.774982Z",
     "shell.execute_reply.started": "2025-04-28T14:59:34.763806Z"
    }
   },
   "outputs": [],
   "source": [
    "def view_clusters(data, labels, ylim = 70, xlabel= 'Biweeks'):\n",
    "    \"\"\"\n",
    "    visualize the different time-series of students belonging to each cluster. \n",
    "    :param data: np.array with students' time-series\n",
    "    :param labels: np.array predicted labels from clustering model\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    _, biweeks = data.shape\n",
    "    clusters = np.unique(labels).shape[0]\n",
    "    fig, axs = plt.subplots(1, clusters, figsize=(16, 4), facecolor='w', edgecolor='k')\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i in range(clusters):\n",
    "        students_cluster = data[labels == i]\n",
    "        number_students = students_cluster.shape[0]\n",
    "        for student in range(number_students):\n",
    "            axs[i].bar(range(biweeks), students_cluster[student], alpha=0.3)\n",
    "        \n",
    "        axs[i].set_ylim([0, ylim])\n",
    "        axs[i].set_title('Group {0}'.format(i))\n",
    "        axs[i].set_ylabel('Hours using platform')\n",
    "        axs[i].set_xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bef920-853c-4d55-94ca-16b68a979903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:35.054696Z",
     "iopub.status.busy": "2025-04-28T14:59:35.052345Z",
     "iopub.status.idle": "2025-04-28T14:59:35.075833Z",
     "shell.execute_reply": "2025-04-28T14:59:35.073147Z",
     "shell.execute_reply.started": "2025-04-28T14:59:35.054588Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_students_group(data, labels):\n",
    "    \"\"\"\n",
    "    Plot the students time-series\n",
    "    :param data: np.array with students' time-series\n",
    "    :param labels: pd.Series indicating the labels of the students\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    for group in np.unique(labels):\n",
    "        subdata = data[labels==group]\n",
    "        subindex = labels[labels==group].index\n",
    "        students, biweeks = subdata.shape\n",
    "\n",
    "        rows = int(np.ceil(students/6))\n",
    "        fig, axs = plt.subplots(rows, 6, figsize=(16, rows*3), sharex=True,\n",
    "                            sharey=True, facecolor='w', edgecolor='k')\n",
    "\n",
    "        axs = axs.ravel()\n",
    "        for i in range(students):\n",
    "            axs[i].bar(range(biweeks), subdata[i], alpha=0.8)\n",
    "            axs[i].set_ylim([0, 50])\n",
    "            axs[i].set_title('Student {0}'.format(subindex[i]))\n",
    "        \n",
    "        fig.suptitle('GROUP {}'.format(group))\n",
    "        fig.supxlabel('Biweek')\n",
    "        fig.supylabel('Usage of platform (hours)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a52622-dc7d-404e-a4f1-bcc583e70f36",
   "metadata": {},
   "source": [
    "Both the Silhouette score and the eigengap heuristic suggest that the optimal number of clusters is 2. We visualize the mean behavior as well as the time series data of the students in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2f5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:35.670260Z",
     "iopub.status.busy": "2025-04-28T14:59:35.669202Z",
     "iopub.status.idle": "2025-04-28T14:59:37.490577Z",
     "shell.execute_reply": "2025-04-28T14:59:37.487911Z",
     "shell.execute_reply.started": "2025-04-28T14:59:35.670136Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "view_clusters(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ddd7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:37.495968Z",
     "iopub.status.busy": "2025-04-28T14:59:37.494862Z",
     "iopub.status.idle": "2025-04-28T14:59:45.030044Z",
     "shell.execute_reply": "2025-04-28T14:59:45.028190Z",
     "shell.execute_reply.started": "2025-04-28T14:59:37.495888Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_students_group(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cbba7-8989-44b0-83be-c719cf8f8c9a",
   "metadata": {},
   "source": [
    "We observe that when using aggregated features, we obtain a \"high effort\" and a \"low effort\" group, i.e. one group of students spending significantly more time on the platform on average than the other group of students. Using aggregated features, we are not able to take into account the shape of the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66943920-d38e-4b66-b18e-5cfa7d6b1c3d",
   "metadata": {},
   "source": [
    "## 2 - Assuming fixed time intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad581578-d3ed-40f5-8a0a-36b51f48603f",
   "metadata": {},
   "source": [
    "Given the fact that all the students have the same number of biweeks (worth a year), the time series of each student has the same length. We can therefore simply use the Euclidean distance to compute the pairwise distances. In order to avoid clustering by the absolute number of hours and capture students individual differences over the semester (i.e. students who work more at the beginning of the semester and then less over the course of the semester) we normalize the data for each student (i.e. within the student's time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a79690-3afd-45e6-ac7f-3ae9d2c585ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:45.032354Z",
     "iopub.status.busy": "2025-04-28T14:59:45.031964Z",
     "iopub.status.idle": "2025-04-28T14:59:45.040195Z",
     "shell.execute_reply": "2025-04-28T14:59:45.038769Z",
     "shell.execute_reply.started": "2025-04-28T14:59:45.032324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data\n",
    "norms = np.linalg.norm(X, axis=1)\n",
    "data_normalized = X / norms[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c54a73-cae5-4d0f-b6b2-125f6c3a1bfa",
   "metadata": {},
   "source": [
    "We then again perform a spectral clustering and visualize the heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b7d36-1d82-4f22-93b7-d98a75b803ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:45.041711Z",
     "iopub.status.busy": "2025-04-28T14:59:45.041437Z",
     "iopub.status.idle": "2025-04-28T14:59:45.077438Z",
     "shell.execute_reply": "2025-04-28T14:59:45.075401Z",
     "shell.execute_reply.started": "2025-04-28T14:59:45.041686Z"
    }
   },
   "outputs": [],
   "source": [
    "S = pairwise_kernels(data_normalized, metric='rbf', gamma=1)\n",
    "W =  get_adjacency(S) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5921d-2014-430c-bf2c-a12d0eeb5417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:45.082607Z",
     "iopub.status.busy": "2025-04-28T14:59:45.081418Z",
     "iopub.status.idle": "2025-04-28T14:59:45.629997Z",
     "shell.execute_reply": "2025-04-28T14:59:45.628330Z",
     "shell.execute_reply.started": "2025-04-28T14:59:45.082527Z"
    }
   },
   "outputs": [],
   "source": [
    "n_cluster_list = range(2, 10)\n",
    "df_labels = get_heuristics_spectral(W, n_cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e906b-49e4-4843-bf48-d1e24fdabd39",
   "metadata": {},
   "source": [
    "The Silhouette score suggests that the optimal number of clusters is 4, while according to the eigengap heuristic, the optimal number of clusters is 2.\n",
    "We therefore visualize the behavior for 2 and 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb73c2-eb9a-49c8-a342-861677998ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:45.631778Z",
     "iopub.status.busy": "2025-04-28T14:59:45.631486Z",
     "iopub.status.idle": "2025-04-28T14:59:47.777138Z",
     "shell.execute_reply": "2025-04-28T14:59:47.774276Z",
     "shell.execute_reply.started": "2025-04-28T14:59:45.631750Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 2\n",
    "view_clusters(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006b31d-70b7-40e8-aa94-e94de8d1d76c",
   "metadata": {},
   "source": [
    "For 2 clusters, we seem to obtain one group with students working at the end of the semester and one group with students at the beginning of the semester. However, when we look into the actual timelines of the students in the clusters, we observe that also students with peaks in the end or no peaks get assigned to group 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23f25e-bd9c-40cd-b78a-da0b828ab9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:47.784307Z",
     "iopub.status.busy": "2025-04-28T14:59:47.782125Z",
     "iopub.status.idle": "2025-04-28T14:59:55.261620Z",
     "shell.execute_reply": "2025-04-28T14:59:55.260534Z",
     "shell.execute_reply.started": "2025-04-28T14:59:47.784216Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_students_group(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288699c7-b175-4264-9ee1-72bdbce3e12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:55.264018Z",
     "iopub.status.busy": "2025-04-28T14:59:55.263613Z",
     "iopub.status.idle": "2025-04-28T14:59:57.363566Z",
     "shell.execute_reply": "2025-04-28T14:59:57.362079Z",
     "shell.execute_reply.started": "2025-04-28T14:59:55.263974Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "view_clusters(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa79ef-1d5b-4fdc-b7f6-27400ae45e20",
   "metadata": {},
   "source": [
    "When using 4 clusters, we get a group with peaks in the beginning (group 2), a group with no peaks (group 1), and two groups (group 0 and group 3) with peaks towards the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0d61f-c4fd-4345-8893-59814cbd5a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T14:59:57.365836Z",
     "iopub.status.busy": "2025-04-28T14:59:57.365550Z",
     "iopub.status.idle": "2025-04-28T15:00:04.739464Z",
     "shell.execute_reply": "2025-04-28T15:00:04.737510Z",
     "shell.execute_reply.started": "2025-04-28T14:59:57.365810Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_students_group(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f80838-68ee-47e9-9377-00b03b249295",
   "metadata": {},
   "source": [
    "We observe that using Euclidean distance, the clustering is very sensitive to the peaks, i.e. tries to exactly align the peaks. If two students i and j do both have peaks in the end but not in the exact same biweek, the pairwise distance between them can get very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f87537-21ab-4b92-b0e2-11c667d46ea2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3- Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ddd6d-0108-4782-a6e5-2eda57d34b56",
   "metadata": {},
   "source": [
    "Dynamic time warping allows us to align to sequences in an optimal way by choosing a window size w larger than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c1fef-b13a-4bee-be18-b3e8e5f06e5e",
   "metadata": {},
   "source": [
    "We first implement a distance function for computing the dynamic time warping distance for a fixed window size w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a891f2-e21e-491d-8a02-a8d36968b6de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:04.741141Z",
     "iopub.status.busy": "2025-04-28T15:00:04.740846Z",
     "iopub.status.idle": "2025-04-28T15:00:04.751340Z",
     "shell.execute_reply": "2025-04-28T15:00:04.748682Z",
     "shell.execute_reply.started": "2025-04-28T15:00:04.741113Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_distance_matrix(X, metric='euclidean', window=2):\n",
    "    \"\"\"\n",
    "    calculates distance matrix given a metric\n",
    "    :param X: np.array with students' time-series\n",
    "    :param metric: str distance metric to compute\n",
    "    :param window: int for DTW\n",
    "    :return: np.array with distance matrix\n",
    "    \"\"\"\n",
    "    norms = np.linalg.norm(X, axis=1)\n",
    "    data_normalized = X / norms[:, np.newaxis]\n",
    "\n",
    "    if metric == 'dtw':\n",
    "        distance_matrix = cdist_dtw(data_normalized,\n",
    "                                    global_constraint='sakoe_chiba',\n",
    "                                    sakoe_chiba_radius=window)\n",
    "    else:\n",
    "        distance_vector = distance.pdist(data_normalized, metric)\n",
    "        distance_matrix = distance.squareform(distance_vector)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49558eb-05fc-455e-9953-09ec1f5d1fb1",
   "metadata": {},
   "source": [
    "We then also implement a function that computes the similarity matrix for us based on the pairwise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4aec95-88ed-4f55-95fc-a9eac56f8b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:04.755598Z",
     "iopub.status.busy": "2025-04-28T15:00:04.754721Z",
     "iopub.status.idle": "2025-04-28T15:00:04.795387Z",
     "shell.execute_reply": "2025-04-28T15:00:04.791774Z",
     "shell.execute_reply.started": "2025-04-28T15:00:04.755520Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_affinity_matrix(D, gamma=1):\n",
    "    \"\"\"\n",
    "    calculates affinity matrix from distance matrix\n",
    "    :param D: np.array distance matrix\n",
    "    :param gamma: float coefficient for Gaussian Kernel\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    S = np.exp(-gamma * D ** 2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a661c6-e944-4d42-833f-f8909b4748c9",
   "metadata": {},
   "source": [
    "We then compute pairwise distances using a window size of 6. Subsequently, we compute the similarity matrix and the adjacency matrix and then again perform spectral clustering and visualize the cluster heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697bd4f-5e8e-4f69-b5e5-58f0519793c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:04.799284Z",
     "iopub.status.busy": "2025-04-28T15:00:04.798416Z",
     "iopub.status.idle": "2025-04-28T15:00:07.076554Z",
     "shell.execute_reply": "2025-04-28T15:00:07.074352Z",
     "shell.execute_reply.started": "2025-04-28T15:00:04.799209Z"
    }
   },
   "outputs": [],
   "source": [
    "D = get_distance_matrix(data, metric='dtw', window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e481875-ef8a-4917-928d-1441c4fc16d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:07.078625Z",
     "iopub.status.busy": "2025-04-28T15:00:07.078230Z",
     "iopub.status.idle": "2025-04-28T15:00:07.086410Z",
     "shell.execute_reply": "2025-04-28T15:00:07.084666Z",
     "shell.execute_reply.started": "2025-04-28T15:00:07.078592Z"
    }
   },
   "outputs": [],
   "source": [
    "S = get_affinity_matrix(D)\n",
    "W = get_adjacency(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a14071-0dc9-4c53-8be9-cee398f85fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:07.089882Z",
     "iopub.status.busy": "2025-04-28T15:00:07.089578Z",
     "iopub.status.idle": "2025-04-28T15:00:07.613969Z",
     "shell.execute_reply": "2025-04-28T15:00:07.611363Z",
     "shell.execute_reply.started": "2025-04-28T15:00:07.089856Z"
    }
   },
   "outputs": [],
   "source": [
    "n_cluster_list = range(2, 10)\n",
    "df_labels = get_heuristics_spectral(W, n_cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a35e1-849f-439b-9ac4-15acac759379",
   "metadata": {},
   "source": [
    "We observe that the Silhouette score suggests that the optimal number of clusters is 3, while the eigengap heuristic suggests 2 clusters. \n",
    "We visualize the clustering solution for k=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7030f16-6e06-44b9-b063-5f1cdaf45c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:07.620967Z",
     "iopub.status.busy": "2025-04-28T15:00:07.617646Z",
     "iopub.status.idle": "2025-04-28T15:00:09.572444Z",
     "shell.execute_reply": "2025-04-28T15:00:09.571364Z",
     "shell.execute_reply.started": "2025-04-28T15:00:07.620862Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "view_clusters(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cba252-e7ce-48a1-b798-d0223bc0ac42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:09.574339Z",
     "iopub.status.busy": "2025-04-28T15:00:09.573862Z",
     "iopub.status.idle": "2025-04-28T15:00:16.638103Z",
     "shell.execute_reply": "2025-04-28T15:00:16.637136Z",
     "shell.execute_reply.started": "2025-04-28T15:00:09.574294Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_students_group(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129eee6-2751-4e45-97bb-184e074e1640",
   "metadata": {},
   "source": [
    "Finally, we play with the window size w. We choose a very small window size (w = 0) and a very large window size (w = 27)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad67ef-4af5-451c-8e33-74cbc5de9191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:16.639790Z",
     "iopub.status.busy": "2025-04-28T15:00:16.639477Z",
     "iopub.status.idle": "2025-04-28T15:00:17.218915Z",
     "shell.execute_reply": "2025-04-28T15:00:17.216945Z",
     "shell.execute_reply.started": "2025-04-28T15:00:16.639762Z"
    }
   },
   "outputs": [],
   "source": [
    "# windows size 0\n",
    "D = get_distance_matrix(data, metric='dtw', window=0)\n",
    "S = get_affinity_matrix(D)\n",
    "W = get_adjacency(S)\n",
    "n_cluster_list = range(2, 10)\n",
    "df_labels = get_heuristics_spectral(W, n_cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1807d421-7fdc-4b7f-92dd-9c51d9bc37d3",
   "metadata": {},
   "source": [
    "Using w=0 is equal to just simply computing Euclidean distance and therefore, we obtain exactly the same results as with the fixed time intervals method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade83d9-724b-4d83-b2bd-faff1d29f223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:17.224206Z",
     "iopub.status.busy": "2025-04-28T15:00:17.223207Z",
     "iopub.status.idle": "2025-04-28T15:00:18.362711Z",
     "shell.execute_reply": "2025-04-28T15:00:18.360691Z",
     "shell.execute_reply.started": "2025-04-28T15:00:17.224003Z"
    }
   },
   "outputs": [],
   "source": [
    "# windows size 27\n",
    "D = get_distance_matrix(data, metric='dtw', window=27)\n",
    "S = get_affinity_matrix(D)\n",
    "W = get_adjacency(S)\n",
    "n_cluster_list = range(2, 10)\n",
    "df_labels = get_heuristics_spectral(W, n_cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7524b5-3361-4acd-9d2e-b54c9d9e7b07",
   "metadata": {},
   "source": [
    "We again visualize the cluster solution as determined by the Silhouette score. Choosing a very large window size (w= 27) leads to the fact that the DTW can align time series across the year (i.e. students with peaks in the beginning can be close to students with peaks in the end of the year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c132268a-b4f5-45eb-b444-9595f4db7621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:18.365430Z",
     "iopub.status.busy": "2025-04-28T15:00:18.364850Z",
     "iopub.status.idle": "2025-04-28T15:00:20.528004Z",
     "shell.execute_reply": "2025-04-28T15:00:20.526744Z",
     "shell.execute_reply.started": "2025-04-28T15:00:18.365381Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "view_clusters(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85125a5-682f-4ad1-9cb3-802d2d7fa416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T15:00:20.529971Z",
     "iopub.status.busy": "2025-04-28T15:00:20.529522Z",
     "iopub.status.idle": "2025-04-28T15:00:27.273576Z",
     "shell.execute_reply": "2025-04-28T15:00:27.272385Z",
     "shell.execute_reply.started": "2025-04-28T15:00:20.529944Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_students_group(data, df_labels[str(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a61920-a737-4b4e-b164-49cb63964c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
