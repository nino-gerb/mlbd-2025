{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04- Extended Exercises on Classification and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jp4ln17R8BNF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel, mutual_info_classif\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnSVIV4Xu_wt",
    "tags": []
   },
   "source": [
    "You are the Senior Data Scientist in a learning platform called LernTime. You have realized that many users stop using the platform and want to increase user retention. For this purpose, you decide to build a model to predict whether a student will stop using the learning platform or not.\n",
    "\n",
    "Your data science team built a data frame in which each row contains the aggregated features per student (calculated over the first 5 weeks of interactions) and the feature `dropout` indicates whether the student stopped using the platform (1) or not (0) before week 10.\n",
    "\n",
    "The dataframe is in the file `lerntime.csv` and contains the following features:\n",
    "- `video_time`: total video time (in minutes) \n",
    "- `num_sessions` total number of sessions\n",
    "- `num_quizzes`: total number of quizzes attempts\n",
    "- `reading_time`: total theory reading time\n",
    "- `previous_knowledge`: standardized previous knowledge\n",
    "- `browser_speed`: standardized browser speed\n",
    "- `device`:  whether the student logged in using a smartphone (1) or a computer (-1)\n",
    "- `topics`: the topics covered by the user\n",
    "- `education`: current level of education (0: middle school, 1: high school, 2: bachelor, 3: master, 4: Ph.D.).\n",
    "- `dropout`: whether the student stopped using the platform (1) or not (0) before week 5.\n",
    "\n",
    "The newest data scientist created two models with an excellent performance. As a Senior Data Scientist, you are suspicious of the results and decide to revise the code. \n",
    "\n",
    "Your task is to:\n",
    "\n",
    "a) Identify the mistakes. In the first cell, add a comment above each line in which you identify an error and explain the error.\n",
    "\n",
    "b) In the second cell, you must correct the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtWJ4sDNvXQP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/lerntime_dropout.csv')\n",
    "\n",
    "y = df['dropout']\n",
    "X = df[['video_time', 'num_sessions', 'num_quizzes', 'reading_time',\n",
    "       'previous_knowledge', 'browser_speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r85IEfMeCgq9"
   },
   "source": [
    "### Task A) Identify the mistakes in the code \n",
    "In the following cell, add a comment above each line in which you identify an error and explain the why it is erroneous.\n",
    "Please start each of your comments with `#ERROR:`. For example:\n",
    "\n",
    "`#ERROR: the RMSE of the model is printed instead of the AUC`\n",
    "\n",
    "`print(\"The AUC of the model is: {}\".format(rmse))          `\n",
    "\n",
    "You may assume that: \n",
    "- all the features are continous and numerical. \n",
    "- the features have already been cleaned and processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Or-X9lyFFVAm"
   },
   "outputs": [],
   "source": [
    "# ERROR: Train-test split should be done before preprocessing steps 1. and 2. to avoid data leakage, \n",
    "# fitting both scaler and selector only on X_train\n",
    "## 1. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## 2. Feature selection (Lasso)\n",
    "print(X.shape)\n",
    "lasso = Lasso(alpha=0.1, random_state=0).fit(X, y)\n",
    "selector = SelectFromModel(lasso, prefit = True)\n",
    "X = selector.transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "## 3. Split the data\n",
    "# ERROR: The split should be done before the feature selection or transformation \n",
    "# to avoid data leaking\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "## Model 1\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=1, random_state=0)\n",
    "# ERROR: Fit should only be called on the train set\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "# ERROR: The adjusted mutual information is not an appropriate score for classification, since it would give\n",
    "# a perfect score even if the predictions are the complete opposite of y_test\n",
    "print(\"Score model 1: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "## Model 2\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, random_state=0)\n",
    "# ERROR: Fit should only be called on the train set\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "# ERROR: The adjusted mutual information is not an appropriate score for classification, since it would give\n",
    "# a perfect score even if the predictions are the complete opposite of y_test\n",
    "print(\"Score model 2: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "# ERROR: The second model has just more complexity and can hence better overfit to the test set, which leaked during training\n",
    "## Discussion\n",
    "# Our second model achieved perfect results with unseen data and outperforms the first model.\n",
    "## This is because we increased the number of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acDnbzGiCnBD"
   },
   "source": [
    "### Task B) Correct the code \n",
    "Correct all the erroneous code in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wkyo3yACcb8"
   },
   "outputs": [],
   "source": [
    "## 1. Split the data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "## 2. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "## 3. Feature selection (Lasso)\n",
    "print(X_train.shape)\n",
    "lasso = Lasso(alpha=0.1, random_state=0).fit(X_train, y_train)\n",
    "selector = SelectFromModel(lasso, prefit = True)\n",
    "X_train = selector.transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "print(X_train.shape)\n",
    "\n",
    "## Model 1\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 1: {}\".format(np.round(balanced_accuracy_score(y_test, preds), 2)))\n",
    "\n",
    "## Model 2\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 2: {}\".format(np.round(balanced_accuracy_score(y_test, preds), 2)))\n",
    "\n",
    "## Discussion\n",
    "# Our first model outperformed the second model.\n",
    "# However, it is not clear why because we change the number of estimators and the maximum depth at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C) Re-write your code using pipelines.\n",
    "Hint: Go over sklearn-pipeline-introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold\n",
    "\n",
    "scalers =  [\n",
    "    StandardScaler(),\n",
    "    'passthrough'] # none\n",
    "\n",
    "feature_selectors = [\n",
    "    SelectFromModel(Lasso(alpha=0.1, random_state=0)),\n",
    "    'passthrough'\n",
    "]\n",
    "\n",
    "steps = [('scaler', StandardScaler()), # preprocessing steps\n",
    "         ('feature_selector', SelectFromModel(Lasso(alpha=0.1, random_state=0))), # Feature selection\n",
    "         ('clf', RandomForestClassifier(random_state=0))]               # Model\n",
    "\n",
    "param_grid = {\n",
    "    'scaler': scalers,\n",
    "    'feature_selector':feature_selectors,\n",
    "    'clf__n_estimators': [10,1000],\n",
    "    'clf__max_depth':[1, None]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "search = GridSearchCV(pipeline, param_grid, n_jobs=-1, cv = 5, scoring = \"balanced_accuracy\")\n",
    "search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.2f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(search.cv_results_)\n",
    "results.sort_values('rank_test_score')[[\n",
    "       'param_clf__max_depth', 'param_clf__n_estimators',\n",
    "       'param_feature_selector', 'param_scaler', 'params', 'mean_test_score', 'std_test_score',\n",
    "       'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[['split0_test_score',\n",
    "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
    "       'split4_test_score', 'mean_test_score', 'std_test_score',]].sort_values('std_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "clean_exam_coding_questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
