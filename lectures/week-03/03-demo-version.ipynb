{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe04b0-b989-4b3e-95cd-a9d35bc4a5d9",
   "metadata": {},
   "source": [
    "# Lecture 03 - Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914e7f2",
   "metadata": {},
   "source": [
    "We recommend using Noto for this lecture tutorial, where we've already installed the dependencies of the pymer4 package and statsmodels.\n",
    "\n",
    "We extended the data with extra features. The feature description is found [here](https://docs.google.com/spreadsheets/d/15UvkrJgTapWispb6tSjMTZh0yJooOsxQ3sWIhKjYM7I/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab80eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Import the linear regression model class\n",
    "from pymer4.models import Lm\n",
    "\n",
    "# Import the lmm model class\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "# Import Gaussian modeling\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"./../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3d17b-04a2-46ba-83c7-50ded717fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data\n",
    "df = pd.read_csv('{}/aggregated_extended_fc.csv'.format(DATA_DIR))\n",
    "df = df.fillna('NaN')\n",
    "list(df.columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161074aa-2d9e-4b94-a8c4-054e7fe3d401",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "We will fit a simple linear regression with the pymer4 library with one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84b504-22ed-4d09-9136-0c4ca1ca4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize linear regression model using 1 predictor (time_in_prob) and sample data\n",
    "model = Lm(\"grade ~ mu_speed_playback_mean\", data=df)\n",
    "\n",
    "# Fit it\n",
    "print(model.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81ac36-ce78-4491-9aad-399b0ad50abe",
   "metadata": {},
   "source": [
    "Let's **visualize the fit** of our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967c333-be2b-483b-92e2-f5dbb9e17660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a regression line\n",
    "x_pred = df.mu_speed_playback_mean\n",
    "y_pred = model.fits\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df.mu_speed_playback_mean, df.grade)\n",
    "plt.plot(x_pred,y_pred, color='red')\n",
    "plt.xlabel(\"Mean playback speed\")\n",
    "plt.ylabel(\"Grade\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c3d22-469c-4a6e-9847-1d4e24d2582b",
   "metadata": {},
   "source": [
    "### Two-Variable Regression\n",
    "\n",
    "Next, we will do a regression with **two variables**. Which of these variables has the larger influence on grade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8b6c6-5408-4d3d-bbe9-dccc9fc4dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with two variables\n",
    "\n",
    "# Initialize model using 2 predictor (time_in_problem) and sample data\n",
    "regression_two_variables = Lm(\"grade ~ ch_time_in_prob_sum + wa_num_subs_perc_correct\", data=df)\n",
    "\n",
    "# Fit regression model\n",
    "regression_two_variables.fit()\n",
    "print(regression_two_variables.coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da7941-0799-43fe-978b-69e145b1a4f4",
   "metadata": {},
   "source": [
    "The two variables have very different scales: one is time in seconds {0, inf} and one is percentage {0, 1}. Therefore, we cannot directly compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fb18d-8819-4c65-9636-77129c447548",
   "metadata": {},
   "source": [
    "To make the coefficients comparable, we will standardize them by computing the **z-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc17bca-3b31-4dad-bcfd-6f1f59915a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z-score for time in problem and percentage correct\n",
    "df['time_in_prob_z'] = (df.ch_time_in_prob_sum - df.ch_time_in_prob_sum.mean())/df.ch_time_in_prob_sum.std()\n",
    "df['percentage_correct_z'] = (df.wa_num_subs_perc_correct - df.wa_num_subs_perc_correct.mean())/df.wa_num_subs_perc_correct.std()\n",
    "\n",
    "# re-compute the regression\n",
    "# Initialize model using 2 predictor (time_in_problem) and sample data\n",
    "regression_comparable = Lm(\"grade ~ time_in_prob_z + percentage_correct_z\", data=df)\n",
    "\n",
    "# fit the regression model\n",
    "regression_comparable.fit()\n",
    "print(regression_comparable.coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a0acc-9faa-4131-9d20-dac9be796bc5",
   "metadata": {},
   "source": [
    "We observe that the **time in problem** attribute has a larger impact on grade than **percentage correct**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b240518e-90a9-4079-b409-e7af66078d29",
   "metadata": {},
   "source": [
    "Another option is to use a MinMax Scaling, i.e. we are not standardizing the features but normalizing them between 0 and 1. We don't need to apply the scaler to the percentage of correct solution as this features is naturally between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939604b-9c11-493c-b14f-485f25cdd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit((df['ch_time_in_prob_sum']).to_numpy().reshape(-1,1))\n",
    "df['time_in_problem_norm'] = scaler.transform((df['ch_time_in_prob_sum']).to_numpy().reshape(-1,1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02255f-f116-4d09-b8e0-370a9695d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-compute the regression\n",
    "# Initialize model using 2 predictor (time_in_problem) and sample data\n",
    "regression_scaled = Lm(\"grade ~ time_in_problem_norm + wa_num_subs_perc_correct\", data=df)\n",
    "\n",
    "# fit the regression model\n",
    "regression_scaled.fit()\n",
    "print(regression_scaled.coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23881c14-b1cf-4ce2-96ac-c0309ebcccad",
   "metadata": {},
   "source": [
    "### Generalized Linear Models\n",
    "\n",
    "Now that we have successfully experimented with regression, we are interested in predicting whether a student will pass/fail a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# compute pass/fail label\n",
    "df['passed'] = df.grade >= 4\n",
    "df['passed'] = df['passed'].astype(int)\n",
    "\n",
    "# logistic regression\n",
    "mod1 = smf.glm(formula='passed ~ wa_num_subs_perc_correct', data=df, family=sm.families.Binomial()).fit()\n",
    "print(mod1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c6a20-0050-4bf5-ab64-c394db5817ed",
   "metadata": {},
   "source": [
    "### Mixed Effect Models\n",
    "\n",
    "Sometimes, we might deal with correlated samples. For example, our data set contains students from different origin. We might hypothesize that students having a similar background (category) behave more similar as they come from the same school/education system.  \n",
    "\n",
    "We will therefore now run a model with a **random intercept**, i.e. we will assume that the intercept depends on the category the students are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caac303-853e-4ff9-bf87-1e306983403d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model instance using 1 predictor with random intercepts and slopes\n",
    "model = Lmer(\"passed ~ (1|category) + wa_num_subs_perc_correct\", data=df, family='binomial')\n",
    "\n",
    "# Fit it\n",
    "print(model.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a48b1-04ba-439a-ae4d-20d52e39dd48",
   "metadata": {},
   "source": [
    "\n",
    "### Regression for Time-Series Data\n",
    "\n",
    "Next, we analyze the data over time as we are dealing with **time series** interactions. First, we create a dataframe containing information about the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80274164-ec55-4a46-919c-4bbda62daec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse the necessary data frames\n",
    "df_ui = (df.loc[:,['user','grade','gender','category','year']]).copy()\n",
    "\n",
    "# compute pass/fail label\n",
    "df_ui['passed'] = (df_ui['grade'] >= 4).astype(int)\n",
    "display(df_ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2871d-fa58-4a77-8b45-8feb9970cf04",
   "metadata": {},
   "source": [
    "Next, we parse the the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4eca46-ace8-45ac-b554-cb25bbfafa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_byweek = pd.read_csv('{}/fc_long_extended.csv'.format(DATA_DIR))\n",
    "display(df_byweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351a3cc-7796-4e23-b30a-6b25aaf2cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_byuser = df_byweek.sort_values(by=['user', 'week']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719ebe2-9e0e-42c5-9166-820b9744e559",
   "metadata": {},
   "source": [
    "We can now run a model over the time series data of the students. In our first task, we are interested in predicting course grade early on during the semester. This type of information can be useful for an instructor in order to be able to provide intervention to struggling students. We will use again the category as a random effect.\n",
    "We will need to train a separate model for each week (i.e. predicting after 1 week of the course, after 2 weeks of the course, after 3 weeks, etc.). However, we will use the same equation for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a469ce-c0d0-4406-ab3b-a4d18efcf17e",
   "metadata": {},
   "source": [
    "**Step 1**: We will write a function that aggregates the features for all weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0907c1a-83b8-4868-b74c-95242ec26c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(df_ui, df_byuser, week_nr):\n",
    "\n",
    "    df_weeknr = df_byuser[df_byuser['week'] < week_nr]\n",
    "    df_return = df_weeknr.groupby(['user']).mean()\n",
    "    df_return['user'] = df_return.index\n",
    "    \n",
    "    # Return df with aggregated features\n",
    "    df_return = df_return.set_index('user').join(df_ui.set_index('user'))\n",
    "    df_return.reset_index()\n",
    "    \n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b825aca-d219-462d-bc6c-2de02170ae86",
   "metadata": {},
   "source": [
    "**Step 2**: We will split the data into a training and test set (20% users in the test set, stratified by pass/fail label). In our case, **data stratification** refers to choosing a sample with the same ratio of pass/fail as the initial dataset, so our training set and our test set are both representative of our original population. If you are interested, you can read more about [stratifying test sets here](https://www.baeldung.com/cs/ml-stratified-sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55f1df-7413-4be2-ac01-2252f70e81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train/test split\n",
    "df_week5 = aggregate_features(df_ui, df_byuser, 5)\n",
    "df_train5, df_test5 = train_test_split(df_week5, test_size=0.2, random_state=0,  stratify=df_week5['passed'])\n",
    "\n",
    "df_week10 = aggregate_features(df_ui, df_byuser, 10)\n",
    "df_train10, df_test10 = train_test_split(df_week10, test_size=0.2, random_state=0,  stratify=df_week10['passed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748c172-be3d-42ef-ab2f-73e245f1ef1a",
   "metadata": {},
   "source": [
    "**Step 3**: We will now train our model on the training data for 5 and 10 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eac53f-7c63-41a2-8df6-e7e3ab90b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a multi-regression model for weeks 5 and 10\n",
    "# Initialize model instance using 1 predictor with random intercepts and slopes\n",
    "model5 = Lmer(\"passed ~ (1|category) +  wa_num_subs_perc_correct\", data=df_train5, family='binomial')\n",
    "model10 = Lmer(\"passed ~ (1|category) +  wa_num_subs_perc_correct\", data=df_train10, family='binomial')\n",
    "\n",
    "# Fit the models\n",
    "print(model5.fit())\n",
    "print(model10.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324149c1-2210-46a4-8b03-996335ea67c3",
   "metadata": {},
   "source": [
    "**Step 4**: We predict on the test data and check the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a3efd-1478-4452-86a7-156847ea7ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test data for weeks 5, 10\n",
    "predictions5 = model5.predict(df_test5, verify_predictions=False)\n",
    "rmse5 = mean_squared_error(df_test5['passed'], predictions5, squared=False)\n",
    "\n",
    "predictions10 = model10.predict(df_test10, verify_predictions=False)\n",
    "rmse10 = mean_squared_error(df_test10['passed'], predictions10, squared=False)\n",
    "\n",
    "print(rmse5)\n",
    "print(rmse10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
